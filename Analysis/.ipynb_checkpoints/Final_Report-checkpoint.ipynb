{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitch Stream Recommendation\n",
    "**Name:** Matthew Susanto  \n",
    "**Project:** Twitch Live stream recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "\n",
    "# Model Training\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Misc\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "According to Forbes, live streaming has a 99% YOY growth in 2020. With the growth of live streaming, many companies such as Chipotle, KFC, Lexus, and many more, are investing in sponsoring streamers. These sponsors may include large events or smaller Ad segments.  \n",
    "\n",
    "Streamers generally stream for about 3 - 6 hours and some maybe 10 hours. The length of these streams makes it difficult to keep the audience's retention rate. Therefore, streamers strive to create a connection between themselves and the audience; the content and entertainment aspect of the stream is very important to keep the audience's retention. The biggest difference between video streaming services like YouTube and live streaming like Twitch is in their content. YouTube videos usually have one focus in each video. For example, for gaming, a YouTube video would only be about 1 game. On the other hand, Twitch streams can have multiple content. For example, a twitch stream might include some video reacting followed with 3 different games. Therefore, recommending streams using the same method as YouTube videos would not be appropriate.  \n",
    "\n",
    "In this paper, I will create a recommend new streamers based on my viewing habits. In order to achieve this, I will need to:\n",
    "1. Collect personal data and streamer data\n",
    "2. Find connections between streamers and chatters\n",
    "3. Create a recommendation index  \n",
    "\n",
    "# Data collection\n",
    "Data collection is probably the most important part of recommending streams. There are two parts into data collection: my personal viewing habits and live stream data. For my personal viewing habits, I will need data about streamers that I follow and minutes watched for each streamer; the minutes watched will show how much I like a certain streamer. These data can be gathered by requesting Twitch.  \n",
    "\n",
    "A larger portion of this data collection step was collecting data about each streamer. First, since there are over a million streamers on Twitch, I decided to only use the top 100 streamers on the platform. The top 100 streamers are determined by the number of subscriptions. By scraping websites like SocialBlade and TwitchTracker, we can gather the top 100 streamers on the platform based on subscriptions; the scraping is done through using beautiful soup. After getting all the top 100 streamers, we can proceed in gathering more information about their streams. Some data that we can gather from the streams are chatters (the people in the chat box), game played throughout the stream, title, tags and time of stream. To get these data, we can use the Twitch API. The Twitch API allows us to gather public data regarding a certain stream. There are two APIs that I used. The first API gathers data about viewers/chatters and the second API gathers the stream metadata.  \n",
    "\n",
    "The next step would be gathering the data. Since we would need to gather data for multiple streams, we need a way to know when a streamer goes live. One way was to set a websocket connection and get a response when a streamer goes live. However, this would mean that I gather data only during the start of the stream. As aforementioned, streams tend to vary in content. With this in mind we would actually need gather data multiple times during the stream. Therefore, we could set some sort of schedule to gather data at increments. We can do this by creating a CRON scheduler. A CRON scheduler will run a script at set interval of times. For this project I set a scheduler to run in 3 hour increments. Next, I saved these values into a database on MongoDB since saving raw text files would take up a larger space. This was also done to avoid any errors when opening and closing a file since using a database only requires persistent connection. MongoDB allows about 500 MB of free storage. With this constraint, I was able to run the scheduler for about 2 weeks which gathered about 1800 stream data.\n",
    "\n",
    "# Part 1: Exploration\n",
    "The first part of the report is exploration. I will focus on looking at my personal data and creating connections between streamers and chatters. Before exploring the data, I will need to clean and analyze some of the datasets that I got from Twitch. After requesting my personal data from Twitch, I recieved 6 different datasets: ads, chats_cheers_sub_notifications, follow_unfollow, minutes_watched, pages_viewed, and videos_played."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"../data/\"\n",
    "minutes_watched = \"pretator21_minutes_watched.csv\"\n",
    "follow_unfollow = \"pretator21_follow_unfollow.csv\"\n",
    "video_played = \"pretator21_video_s_played.csv\"\n",
    "page_viewed = \"pretator21_pages_viewed.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_watched_data = pd.read_csv(PATH+minutes_watched)\n",
    "fol_unfol_data = pd.read_csv(PATH+follow_unfollow)\n",
    "vid_played_data = pd.read_csv(PATH+video_played)\n",
    "page_view_data = pd.read_csv(PATH+page_viewed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_watched_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fol_unfol_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_played_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_view_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will only use minutes_watched and follow_unfollow since the other datasets do not really give any useful information about the streamers I watch. First we can clean and analyze the follow_unfollow dataset. I will check if the dataset includes other values other than follow and unfollow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fol_unfol_data[\"event_type\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the dataset includes those that are unfollowed, I will delete rows that represent channels that I unfollowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fol_unfol_data[fol_unfol_data[\"event_type\"] == 'unfollow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfollowed = list(fol_unfol_data[fol_unfol_data[\"event_type\"] == \"unfollow\"][\"channel\"])\n",
    "channels_unfollowed = fol_unfol_data[fol_unfol_data[\"channel\"].isin(unfollowed)]\n",
    "channels_unfollowed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the only channel that I followed after unfollowing is \"dspstanky\". So, we should remove all unfollowed channels from the data and only focus on those that are followed. For channels like \"dspstanky\", I will keep only the latest follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "follow_data = fol_unfol_data.drop([2,7,18,19,23,54])\n",
    "follow_data[\"event_type\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the dataset includes only followed streamers, we can continue with the exploration. Another aspect of the data that needs to be cleaned is duplicate values. Since users can only follow Twitch streamers once, it is impossible to have multiple follows without unfollows in between. However, this problem happens in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "follow_data[\"channel\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "follow_data[follow_data[\"channel\"] == \"valorant\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that the day in which the streamer is followed occurs on the same dates. Since there are also no unfollows, this would probably be a result of some glitch. To keep the data clean, I will include only unique streamers. This shouldn't affect the data since duplicate follows have no meaning in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_channels = follow_data[\"channel\"].unique()\n",
    "cleaned_follow = follow_data.drop_duplicates(subset=[\"channel\"])\n",
    "cleaned_follow[\"channel\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the channels sorted by followed date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_follow[[\"day\", \"channel\"]].sort_values(by=\"day\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we should look at the followed channels sorted by the total watch time. This should provide more insights on which channels I enjoy watching. To do this I will use the \"minutes_watched\" dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_watched_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "followed_min_watch = min_watched_data[min_watched_data[\"channel_name\"].isin(unique_channels)]\n",
    "followed_min_watch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the dataset, the minutes watched is represented as integers in the context column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "followed_min_watch.groupby(\"channel_name\").sum()[\"context\"].sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just by looking at the data above, from my own knowledge, it seems like there are multiple channels that are not in the list of followed channels. So, instead of using this dataset, I will instead take the followers data from the twitch api. This will give a more current and accurate followers list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "header = {\"Client-ID\": \"7cud78uflv2g253xvxhle6jtcal7dk\", \"Authorization\": \"Bearer eonmsxbqksmjgut5knq4ugaetp0ljf\"}\n",
    "from_id = 162289168\n",
    "\n",
    "follow_data = []\n",
    "\n",
    "def get_user_follows(from_id, first=100, after=None):\n",
    "    # Get who a user follows based on an id\n",
    "    if after != None:\n",
    "        response = requests.get('https://api.twitch.tv/helix/users/follows?from_id={from_id}&after={after}&first={first}'.format(from_id=from_id, after=after, first=first), headers=header)\n",
    "    else:\n",
    "        response = requests.get('https://api.twitch.tv/helix/users/follows?from_id={from_id}&first={first}'.format(from_id=from_id,first=first), headers=header)\n",
    "    return response\n",
    "\n",
    "still_paginate = True\n",
    "cursor = None\n",
    "\n",
    "# The API returns a pagination key after every 100 objects.\n",
    "# We keep the cursor to the next pagination so we can get the next 100 items\n",
    "while still_paginate:\n",
    "    if cursor == None:\n",
    "        res=get_user_follows(from_id)\n",
    "        print(res)\n",
    "        still_paginate = len(res.json()['pagination']) > 0\n",
    "        follow_data += res.json()['data']\n",
    "        if still_paginate:\n",
    "            cursor = res.json()['pagination']['cursor']\n",
    "    else:\n",
    "        res=get_user_follows(from_id, after=cursor)\n",
    "        still_paginate = len(res.json()['pagination']) > 0\n",
    "        follow_data += res.json()['data']\n",
    "        if still_paginate:\n",
    "            cursor = res.json()['pagination']['cursor']\n",
    "len(follow_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "follow_df = pd.DataFrame(follow_data)\n",
    "follow_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a more accurate list my followers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "follow_df.sort_values(by=\"followed_at\")[\"to_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "follow_list = list(follow_df[\"to_login\"])\n",
    "followed_min_watch = min_watched_data[min_watched_data[\"channel_name\"].isin(follow_list)]\n",
    "channels_by_watch_time = followed_min_watch.groupby(\"channel_name\").sum()[\"context\"].sort_values(ascending=False)\n",
    "channels_by_watch_time[\"xqcow\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=channels_by_watch_time[:20].index, y=channels_by_watch_time[:20])\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that xqcow is the most watched channel compared to other streamers. Next, we can look at games. Specifically, we can look at which games are most common between the streamers and also Twitch in general. Do do this, I will need to use the dataset collected by the APIs. We can start by analyzing and collecting the dataset from the MongoDB database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "client = MongoClient(\"mongodb+srv://dbUser:dbUserPassword@cluster0.jemq8.mongodb.net/myFirstDatabase?retryWrites=true&w=majority\")\n",
    "db = client[\"stream_data\"]\n",
    "collection = db[\"streams\"]\n",
    "\n",
    "print(db.list_collection_names())\n",
    "\n",
    "documents = []\n",
    "for document in collection.find():\n",
    "    documents.append(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatters = pd.DataFrame(documents)\n",
    "chatters.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will start by looking at the trend in games for Twitch overall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(chatters['game_name'].value_counts().keys()[:10], chatters['game_name'].value_counts()[:10])\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that Just Chatting is the most common game played among the top 100 streamers. Next, we can look at the overall trend among the followed streamers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "followed_chatters = chatters[chatters['user_login'].isin(follow_list)]\n",
    "sns.barplot(followed_chatters['game_name'].value_counts().keys()[:10], followed_chatters['game_name'].value_counts()[:10])\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just Chatting is still the most common game. However, games like CSGO, League of Legends, Fortnite and Dota are not in the top 10 games. With this visualization, the top 4 games that my followed streamers play is Just Chatting, Valorant, New world, and Grand Theft Auto V. Eventhough, we know that these are the top 4 games, I cannot conclude that these are the type of games I enjoy watching. This is the main difference between YouTube videos and Twitch streams. This is because streamers tend to play multiple games in one stream. Instead, we can look at specific streamers and games they commonly play. This will give a better picture on the type of games I enjoy watching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_chatters = followed_chatters.groupby([\"user_login\", \"game_name\"]).size()\n",
    "grouped_chatters = grouped_chatters.reset_index()\n",
    "grouped_chatters = grouped_chatters.rename({0: \"count\"}, axis=1)\n",
    "grouped_chatters.sort_values([\"user_login\", \"count\"], ascending=False)[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the data above we see that the games that are played by the streamers are quite random. There is no definite set that defines a streamer. A better way to show which streamers I enjoy watching is by visualizing how similar each streamer is. Perhaps there are common games that multiple streamers play. This could be a reason why I followed them. To do this, I can draw a network graph to show connections between streamers in my followed list and the top 100 streamers. There are three elements to create a network graph: source, target, and edges. To show if games determine similarity between streamers, we can create and edge from one streamer to the next if they played the same game. This will help me recommend streamers based on similarities between them.\n",
    "\n",
    "# Graph Visualization: Part I\n",
    "In the span of two weeks in October, not all 100 streamers streamed. In fact, there were only 79 unique streamers this month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(chatters['user_login'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first graph that we could visualize is a streamer to streamer connection based on the games they play. To get the data to create the graph, we can group the user_login and count the number of times they play a game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatters_group = chatters.groupby(['user_login', 'game_name']).count()[\"_id\"]\n",
    "pd.DataFrame(chatters_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this information, we have each user and the game that they played. We can use this to create the network graph. To do this we first make a dictionary of values where the key is the game name and value is a list of streamers who played the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_stream_list = list(chatters_group.index)\n",
    "# Create dictionary of game-streamer\n",
    "streamer_dict = {}\n",
    "for stream in game_stream_list:\n",
    "    if stream[1] not in streamer_dict:\n",
    "        streamer_dict[stream[1]] = [stream[0]]\n",
    "    else:\n",
    "        streamer_dict[stream[1]].append(stream[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create an adjacency list for the graph. The adjacency list will look like the following: {streamer_1: {streamer_2: weight}}. The weight will represent how many common games are played between the 2 streamers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {streamer: {streamer_2: 1}}\n",
    "streamer_connection_dict = {}\n",
    "for game in streamer_dict:\n",
    "    for streamer in streamer_dict[game]:\n",
    "        if streamer not in streamer_connection_dict:\n",
    "                streamer_connection_dict[streamer] = {}\n",
    "        for streamer_2 in streamer_dict[game]:\n",
    "            if streamer_2 != streamer:\n",
    "                if streamer_2 not in streamer_connection_dict[streamer]:\n",
    "                    streamer_connection_dict[streamer][streamer_2] = 1\n",
    "                else:\n",
    "                    streamer_connection_dict[streamer][streamer_2] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wil be using pyviz to create the network graph. This is because pyviz allows interactivity and analyzing with this tool will be simpler. I will create a function to generate random colors that can be used to represent groups/clusters in the network graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will be used to assign a random color to nodes\n",
    "import random\n",
    "\n",
    "def get_random_color():\n",
    "    color = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)])\n",
    "                 for i in range(1)]\n",
    "    return color\n",
    "get_random_color()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first network, I will draw connections for streamers in the top 100 list. The colors on each node, will represent groups of streamers determined by how many games they have in common. I will use 3 games as a threshold to group streamers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw interactive graph based on the games that they play\n",
    "network = Network(height='750px', width='100%', bgcolor='#222222', font_color='white', notebook=True)\n",
    "network.repulsion(node_distance=100, central_gravity=0.2, spring_length=200, spring_strength=0.05,\n",
    "damping=0.09)\n",
    "node_color = {}\n",
    "\n",
    "for node in streamer_connection_dict:\n",
    "    for edge in streamer_connection_dict[node]:\n",
    "        src = node\n",
    "        target = edge\n",
    "        width = streamer_connection_dict[node][edge]\n",
    "        \n",
    "        if width > 1:\n",
    "            if node not in node_color:\n",
    "                color = get_random_color()[0]\n",
    "                node_color[node] = color\n",
    "                node_color[edge] = color\n",
    "            elif node in node_color:\n",
    "                node_color[edge] = node_color[node]\n",
    "        else:\n",
    "            if node not in node_color:\n",
    "                color = get_random_color()[0]\n",
    "                node_color[node] = color\n",
    "            if edge not in node_color:\n",
    "                node_color[edge] = get_random_color()[0]\n",
    "            \n",
    "        network.add_node(src, src, title=src, color=node_color[node])\n",
    "        network.add_node(target, target, title=target, color=node_color[edge])\n",
    "        network.add_edge(src, target, value=width)\n",
    "neighbor_map = network.get_adj_list()\n",
    "\n",
    "for node in network.nodes:\n",
    "    node['title'] += ' Neighbors:<br>' + '<br>'.join(neighbor_map[node['id']])\n",
    "    node['value'] = len(neighbor_map[node['id']])\n",
    "\n",
    "network.show_buttons(filter_=['physics']) \n",
    "    \n",
    "network.show('top_100_streamer.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While its a little bit difficult to see connections, we can see that there are alot of green clusters. For example, streamers like kyedae, aceu, lirik, forsen, itztimmy, and more, are grouped into one cluster since they play the similar games at least 2 times. Furthermore, the network graph utilizes physics to group clusters by connection. This means that clusters that are closer together, are more interconnected than those that are further away. In the graph above, the nodes that are in the center are very closely connected and clustered together which means that those streamers share alot of common games. However, streamers like swagg or brawlhalla are far from the center since they only have 1 or 2 connections to nodes in the center. \n",
    "\n",
    "Next, we can look at the connections between my followed streamers, and those in the top 100. Note that not all followed streamers are in the top 100 so the number of nodes will be lesser than the number of followed streamers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Network(height='750px', width='100%', bgcolor='#222222', font_color='white', notebook=True)\n",
    "network.repulsion(node_distance=100, central_gravity=0.2, spring_length=200, spring_strength=0.05,\n",
    "damping=0.09)\n",
    "node_color = {}\n",
    "\n",
    "for node in streamer_connection_dict:\n",
    "    for edge in streamer_connection_dict[node]:\n",
    "        src = node\n",
    "        target = edge\n",
    "        width = streamer_connection_dict[node][edge]\n",
    "        \n",
    "        if node in follow_list:\n",
    "            node_color[node] = \"#9E829C\"\n",
    "        else:\n",
    "            node_color[node] = \"#3A3E3B\"\n",
    "        if edge in follow_list:\n",
    "            node_color[edge] = \"#9E829C\"\n",
    "        else:\n",
    "            node_color[edge] = \"#3A3E3B\"\n",
    "                \n",
    "        network.add_node(src, src, title=src, color=node_color[node])\n",
    "        network.add_node(target, target, title=target, color=node_color[edge])\n",
    "        network.add_edge(src, target, value=width)\n",
    "neighbor_map = network.get_adj_list()\n",
    "\n",
    "for node in network.nodes:\n",
    "    node['title'] += ' Neighbors:<br>' + '<br>'.join(neighbor_map[node['id']])\n",
    "    node['value'] = len(neighbor_map[node['id']])\n",
    "\n",
    "network.show_buttons(filter_=['physics']) \n",
    "    \n",
    "network.show('followed_stream_top_100.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the graph above a very small portion of the top 100 streamers are actually streamers that I follow. Furthermore, by looking at where they are clustered could give us an intuition on which streamers are similar to those that I follow. For example xqcow, has a lot of connections to streamers inside the center, some with weights that are large. An example is xqcow and buddha. Just from the graph alone, the edge weight is thick which means that they have multiple common games. This could help us gather streamer to streamer similarities.\n",
    "\n",
    "Next, we can look at only followed streamers and group them by game. This will provide insight on whether games affect follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Network(height='750px', width='100%', bgcolor='#222222', font_color='white', notebook=True)\n",
    "network.repulsion(node_distance=100, central_gravity=0.2, spring_length=200, spring_strength=0.05,\n",
    "damping=0.09)\n",
    "node_color = {}\n",
    "\n",
    "for node in streamer_connection_dict:\n",
    "    for edge in streamer_connection_dict[node]:\n",
    "        src = node\n",
    "        target = edge\n",
    "        width = streamer_connection_dict[node][edge]\n",
    "        \n",
    "        if width > 1:\n",
    "            if node not in node_color:\n",
    "                color = get_random_color()[0]\n",
    "                node_color[node] = color\n",
    "                node_color[edge] = color\n",
    "            elif node in node_color:\n",
    "                node_color[edge] = node_color[node]\n",
    "        else:\n",
    "            if node not in node_color:\n",
    "                color = get_random_color()[0]\n",
    "                node_color[node] = color\n",
    "            if edge not in node_color:\n",
    "                node_color[edge] = get_random_color()[0]\n",
    "        \n",
    "        if node in follow_list and edge in follow_list:\n",
    "            network.add_node(src, src, title=src, color=node_color[node], value=int(channels_by_watch_time[node]))\n",
    "            network.add_node(target, target, title=target, color=node_color[edge], value=int(channels_by_watch_time[edge]))\n",
    "            network.add_edge(src, target, value=width)\n",
    "neighbor_map = network.get_adj_list()\n",
    "\n",
    "for node in network.nodes:\n",
    "    node['title'] += ' Neighbors:<br>' + '<br>'.join(neighbor_map[node['id']])\n",
    "\n",
    "network.show_buttons(filter_=['physics']) \n",
    "    \n",
    "network.show('streamergraph.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the graph above, we see that there is a large amount of streamers that are similar. Most streamers that are in the center of the graph, play similar games. That are a coupl outliers such as hiko, ninja, valorant, mizkif, ludwig, shroud and npmlol that are not apart of any groups. This could be becuase they are not \"variety streamers\". A variety streamer is someone who plays multiple games in one or more streams. For example, from personal knowledge, xqcow, is a variety streamer. Since xqcow plays a larger variety of games, there is a higher chance that he plays similar games with more streamers multiple times. on the other hand, streamers like mizkif are mainly in the Just Chatting section. This might be an indicator that most streamers that I follow are variety streamers.\n",
    "\n",
    "To answer the question, the streamers that I follow are mainly variety streamers. For the most part, the streamers all play similar games since most of them are colored the same and are clustered in the center. For the next part, I can find out which streamers are variety streamers and what a user-streamer graph looks like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Visualization: Part 2\n",
    "For the next part of the graph visualization, we can look at how streamers are connected to each other based on common chatters. This will show common communities between streamers. First, I will have to create a dictionary of the following form: {chatter: {streamer: 1}}. This way I can group streamers together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer_streamer = chatters[[\"viewers\", \"user_login\"]]\n",
    "viewer_dict = {}\n",
    "for i in range(len(viewer_streamer[\"user_login\"])):\n",
    "    for viewer in viewer_streamer[\"viewers\"][i]:\n",
    "        if viewer not in viewer_dict:\n",
    "            viewer_dict[viewer] = {viewer_streamer[\"user_login\"][i]: None}\n",
    "        else:\n",
    "            viewer_dict[viewer][viewer_streamer[\"user_login\"][i]] = None\n",
    "viewer_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I will convert the dictionary to an adjacency list for streamers: {streamer: {streamer_2: 1}}. This will result in a similar adjancency to the previous graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streamer_dict = {}\n",
    "\n",
    "for viewer in viewer_dict:\n",
    "    for streamer in viewer_dict[viewer]:\n",
    "        if streamer not in streamer_dict:\n",
    "            streamer_dict[streamer] = {}\n",
    "        for streamer_2 in viewer_dict[viewer]:\n",
    "            if streamer_2 != streamer:\n",
    "                if streamer_2 in streamer_dict[streamer]:\n",
    "                    streamer_dict[streamer][streamer_2] += 1\n",
    "                else:\n",
    "                    streamer_dict[streamer][streamer_2] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streamer_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the adjacency list, we can visualize it in a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Network(height='750px', width='100%', bgcolor='#222222', font_color='white', notebook=True)\n",
    "network.barnes_hut(central_gravity=0.2, spring_length=200, spring_strength=0.05,\n",
    "damping=0.09)\n",
    "for node in streamer_dict:\n",
    "    for edge in streamer_dict[node]:\n",
    "        src = node\n",
    "        target = edge\n",
    "        width = streamer_dict[node][edge]\n",
    "        \n",
    "        network.add_node(src, src, title=src)\n",
    "        network.add_node(target, target, title=target)\n",
    "        network.add_edge(src, target, value=width)\n",
    "\n",
    "neighbor_map = network.get_adj_list()\n",
    "\n",
    "for node in network.nodes:\n",
    "    node['title'] += ' Neighbors:<br>' + '<br>'.join(neighbor_map[node['id']])\n",
    "    node['value'] = len(neighbor_map[node['id']])\n",
    "\n",
    "network.show_buttons(filter_=['physics']) \n",
    "    \n",
    "network.show('streamer_chatter.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the graph above, we can see that most of the top 100 streamers have similar communities. However, streamers that are pulled towards each other are generally more common. Visually this is very difficult to see which is why we would need an index to determine how similar two streamers are. There are two different indexes that could help us: Jaccard and Adamic/Adar. To perform these two indexes, I will use networkx.  \n",
    "\n",
    "I will first apply the index to the streamer-chatter graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_index(graph: nx.Graph, streamer):\n",
    "    jaccard_rank = []\n",
    "    adj_list = dict(graph.adjacency())\n",
    "    \n",
    "    for edges in adj_list[streamer]:\n",
    "        pred = nx.jaccard_coefficient(graph, [(streamer, edges)])\n",
    "        for u, v, p in pred:\n",
    "            jaccard_rank.append((v, p))\n",
    "    \n",
    "    return sorted(jaccard_rank, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "def adamic_adar_index(graph: nx.Graph, streamer):\n",
    "    adamic_rank = []\n",
    "    adj_list = dict(graph.adjacency())\n",
    "    \n",
    "    for edges in adj_list[streamer]:\n",
    "        pred = nx.adamic_adar_index(graph, [(streamer, edges)])\n",
    "        for u, v, p in pred:\n",
    "            adamic_rank.append((v, p))\n",
    "    \n",
    "    return sorted(adamic_rank, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streamer_chatter = nx.Graph(streamer_dict)\n",
    "jaccard_index(streamer_chatter, \"xqcow\")[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adamic_adar_index(streamer_chatter, \"xqcow\")[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the indexes are very similar to each other however they are not exactly the same. Before testing the indexes, we can check what the indexes look like for the streamer-game graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streamer_game = nx.Graph(streamer_connection_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard_index(streamer_game, \"mizkif\")[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adamic_adar_index(streamer_game, \"mizkif\")[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard_index(streamer_game, \"xqcow\")[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even with personal knowledge, it is very difficult to see which index creates better recommendations. We can simply test the indexes by predicting which streamers I would follow. We can split the followed list into test and train sets. Since the followed list is very small, we can use some version of K-Fold cross-validation where we randomly select sections of the data as test sets K times. I will set an arbitrary threshold of the top N index.  \n",
    "\n",
    "First, I will find the rank relative to the size of the index list for each index. The reason I am going to use the relative rank is because a rank 6 and 7 does not mean much if the list are of different lengths. However, if it the rank is 0.3, it is in the 70th percentile. A lower number means that the index concludes that the streamer is strongly connected to a followed streamer. We can then calculate the mean for each fold in the cross-validation and find the overall average for each index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split followers train and test split with 10 splits\n",
    "# Calculate the index for each person in the train set\n",
    "# Find the rank of where the streamer is in relative to the size of the list\n",
    "\n",
    "def find_k_fold_average(index, graph, n_splits=5):\n",
    "    kf = KFold(n_splits=n_splits)\n",
    "    top_100_streamer = list(chatters['user_login'])\n",
    "    follow_100 = follow_df[follow_df[\"to_login\"].isin(top_100_streamer)]['to_login']\n",
    "    follow_list = list(follow_100)\n",
    "    epoch_average = []\n",
    "\n",
    "    for train, test in kf.split(follow_list):\n",
    "        train_list = [follow_list[x] for x in train]\n",
    "        test_list = [follow_list[x] for x in test]\n",
    "        average_rank = []\n",
    "\n",
    "        for streamer in train_list:\n",
    "            streamer_list = index(graph, streamer)\n",
    "            for idx, streamer_2 in enumerate(streamer_list):\n",
    "                if streamer_2[0] in test_list:\n",
    "                    average_rank.append(idx/len(streamer_list))\n",
    "        epoch_average.append(np.mean(average_rank))\n",
    "    return epoch_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(find_k_fold_average(jaccard_index, streamer_chatter, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(find_k_fold_average(adamic_adar_index, streamer_chatter, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(find_k_fold_average(jaccard_index, streamer_game, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(find_k_fold_average(adamic_adar_index, streamer_game, 15))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
